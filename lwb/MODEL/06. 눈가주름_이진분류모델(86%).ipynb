{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import crop\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _04 : 오른쪽 눈 주름(r_perocular_wrinkle)에 대해 bbox_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file D:\\final_project_backup\\FINAL_DATA\\한국인 피부상태 측정 데이터\\Training\\labels\\pad\\0138\\0138_02_F_03.json: 'NoneType' object is not iterable\n",
      "Error processing file D:\\final_project_backup\\FINAL_DATA\\한국인 피부상태 측정 데이터\\Training\\labels\\pad\\0823\\0823_02_F_03.json: 'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "label_key = \"_F_03.json\"\n",
    "annotation_key = \"l_perocular_wrinkle\"\n",
    "image_data, target_data = crop.process_files(label_key, annotation_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images processed: 2572\n",
      "Number of targets processed: 2572\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of images processed: {len(image_data)}\")\n",
    "print(f\"Number of targets processed: {len(target_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지, 타겟 데이터 저장\n",
    "with open(f'{annotation_key}_image_data.pkl', 'wb') as f:\n",
    "    pickle.dump(image_data, f)\n",
    "\n",
    "with open(f'{annotation_key}_target_data.pkl', 'wb') as f:\n",
    "    pickle.dump(target_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "with open(f'{annotation_key}_image_data.pkl', 'rb') as f:\n",
    "    image_data = pickle.load(f)\n",
    "\n",
    "with open(f'{annotation_key}_target_data.pkl', 'rb') as f:\n",
    "    target_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 3, Count: 380\n",
      "Value: 0, Count: 180\n",
      "Value: 1, Count: 863\n",
      "Value: 4, Count: 231\n",
      "Value: 2, Count: 384\n",
      "Value: 5, Count: 270\n",
      "Value: 6, Count: 264\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "values_list = list(target_data.values())\n",
    "value_counts = Counter(values_list)\n",
    "\n",
    "for value, count in value_counts.items():\n",
    "    print(f\"Value: {value}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이진분류(0,1)과 (3,4,5,6)로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_classes(target_data):\n",
    "    binary_target_data = {}\n",
    "    for key, value in target_data.items():\n",
    "        if value in [0, 1]:\n",
    "            binary_target_data[key] = '10'\n",
    "        elif value in [3, 4, 5, 6]:\n",
    "            binary_target_data[key] = '20'\n",
    "        else:\n",
    "            binary_target_data[key] = value\n",
    "    \n",
    "    return binary_target_data\n",
    "\n",
    "binary_target_data = merge_classes(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 20, Count: 1145\n",
      "Value: 10, Count: 1043\n"
     ]
    }
   ],
   "source": [
    "filtered_target_data = {key: value for key, value in binary_target_data.items() if value in ['10', '20']}\n",
    "\n",
    "values_list = list(filtered_target_data.values())\n",
    "value_counts = Counter(values_list)\n",
    "\n",
    "for value, count in value_counts.items():\n",
    "    print(f\"Value: {value}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X: 2188, Length of y: 2188\n"
     ]
    }
   ],
   "source": [
    "common_keys = set(image_data.keys()) & set(filtered_target_data.keys())\n",
    "\n",
    "# 데이터 정렬\n",
    "filtered_image_data = {key: image_data[key] for key in common_keys}\n",
    "filtered_target_data = {key: filtered_target_data[key] for key in common_keys}\n",
    "\n",
    "# X와 y 생성\n",
    "X = np.array(list(filtered_image_data.values()))\n",
    "y = np.array(list(filtered_target_data.values()))\n",
    "\n",
    "print(f\"Length of X: {len(X)}, Length of y: {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1750, 128, 128, 3), y_train shape: (1750,)\n",
      "X_test shape: (438, 128, 128, 3), y_test shape: (438,)\n"
     ]
    }
   ],
   "source": [
    "class_mapping = {'10': 0, '20': 1}\n",
    "y = np.array([class_mapping[label] for label in y])\n",
    "X = X / 255.0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 63, 63, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3304769 (12.61 MB)\n",
      "Trainable params: 3304769 (12.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X.shape[1], X.shape[2], X.shape[3])),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')  # 이진 분류 출력층\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(learning_rate=0.0001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 16s 344ms/step - loss: 0.6964 - accuracy: 0.5243 - val_loss: 0.6932 - val_accuracy: 0.4886\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 13s 293ms/step - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6910 - val_accuracy: 0.5886\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 14s 308ms/step - loss: 0.6910 - accuracy: 0.5307 - val_loss: 0.6888 - val_accuracy: 0.5943\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 13s 285ms/step - loss: 0.6909 - accuracy: 0.5136 - val_loss: 0.6914 - val_accuracy: 0.5200\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 12s 268ms/step - loss: 0.6872 - accuracy: 0.5371 - val_loss: 0.6879 - val_accuracy: 0.5400\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 13s 289ms/step - loss: 0.6842 - accuracy: 0.5357 - val_loss: 0.6838 - val_accuracy: 0.5029\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 11s 248ms/step - loss: 0.6807 - accuracy: 0.5486 - val_loss: 0.6785 - val_accuracy: 0.5686\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 11s 247ms/step - loss: 0.6843 - accuracy: 0.5429 - val_loss: 0.6962 - val_accuracy: 0.4914\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 10s 232ms/step - loss: 0.6859 - accuracy: 0.5271 - val_loss: 0.6829 - val_accuracy: 0.5286\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 10s 228ms/step - loss: 0.6704 - accuracy: 0.5736 - val_loss: 0.6865 - val_accuracy: 0.5171\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 10s 231ms/step - loss: 0.6657 - accuracy: 0.5986 - val_loss: 0.6604 - val_accuracy: 0.6314\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 10s 233ms/step - loss: 0.6625 - accuracy: 0.5864 - val_loss: 0.6782 - val_accuracy: 0.5429\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 10s 231ms/step - loss: 0.6507 - accuracy: 0.6293 - val_loss: 0.6390 - val_accuracy: 0.6714\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 10s 239ms/step - loss: 0.6500 - accuracy: 0.6150 - val_loss: 0.6651 - val_accuracy: 0.6343\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 10s 233ms/step - loss: 0.6338 - accuracy: 0.6479 - val_loss: 0.6854 - val_accuracy: 0.5457\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 10s 232ms/step - loss: 0.6506 - accuracy: 0.6100 - val_loss: 0.6136 - val_accuracy: 0.7457\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 10s 233ms/step - loss: 0.6589 - accuracy: 0.6064 - val_loss: 0.6412 - val_accuracy: 0.6629\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 10s 235ms/step - loss: 0.6275 - accuracy: 0.6464 - val_loss: 0.5859 - val_accuracy: 0.7514\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 10s 234ms/step - loss: 0.5872 - accuracy: 0.7021 - val_loss: 0.5581 - val_accuracy: 0.7514\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 10s 230ms/step - loss: 0.5691 - accuracy: 0.7243 - val_loss: 0.5235 - val_accuracy: 0.7600\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 10s 231ms/step - loss: 0.5379 - accuracy: 0.7379 - val_loss: 0.5465 - val_accuracy: 0.7257\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 10s 232ms/step - loss: 0.5231 - accuracy: 0.7536 - val_loss: 0.4799 - val_accuracy: 0.7743\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 10s 232ms/step - loss: 0.5175 - accuracy: 0.7429 - val_loss: 0.5935 - val_accuracy: 0.6514\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 10s 237ms/step - loss: 0.5128 - accuracy: 0.7650 - val_loss: 0.4874 - val_accuracy: 0.7686\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 11s 252ms/step - loss: 0.4804 - accuracy: 0.7764 - val_loss: 0.4637 - val_accuracy: 0.7971\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 12s 282ms/step - loss: 0.4627 - accuracy: 0.7929 - val_loss: 0.4677 - val_accuracy: 0.7800\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 11s 254ms/step - loss: 0.4739 - accuracy: 0.7771 - val_loss: 0.4368 - val_accuracy: 0.8114\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 12s 263ms/step - loss: 0.4507 - accuracy: 0.7986 - val_loss: 0.4384 - val_accuracy: 0.8229\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 11s 256ms/step - loss: 0.4303 - accuracy: 0.8071 - val_loss: 0.4195 - val_accuracy: 0.8086\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 11s 250ms/step - loss: 0.4221 - accuracy: 0.8029 - val_loss: 0.4181 - val_accuracy: 0.8114\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 10s 234ms/step - loss: 0.4339 - accuracy: 0.8021 - val_loss: 0.4048 - val_accuracy: 0.8171\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 10s 230ms/step - loss: 0.4150 - accuracy: 0.8129 - val_loss: 0.4176 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 11s 240ms/step - loss: 0.4019 - accuracy: 0.8171 - val_loss: 0.3931 - val_accuracy: 0.8171\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 11s 249ms/step - loss: 0.4237 - accuracy: 0.8157 - val_loss: 0.4220 - val_accuracy: 0.8029\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 11s 244ms/step - loss: 0.3958 - accuracy: 0.8279 - val_loss: 0.3938 - val_accuracy: 0.8257\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 11s 254ms/step - loss: 0.3836 - accuracy: 0.8414 - val_loss: 0.3784 - val_accuracy: 0.8343\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 10s 236ms/step - loss: 0.3825 - accuracy: 0.8350 - val_loss: 0.3932 - val_accuracy: 0.8257\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 12s 269ms/step - loss: 0.3630 - accuracy: 0.8400 - val_loss: 0.3744 - val_accuracy: 0.8200\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 11s 245ms/step - loss: 0.3712 - accuracy: 0.8350 - val_loss: 0.3648 - val_accuracy: 0.8400\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 11s 259ms/step - loss: 0.3707 - accuracy: 0.8393 - val_loss: 0.4367 - val_accuracy: 0.7886\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 14s 327ms/step - loss: 0.3665 - accuracy: 0.8371 - val_loss: 0.3664 - val_accuracy: 0.8457\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 11s 249ms/step - loss: 0.3627 - accuracy: 0.8443 - val_loss: 0.3789 - val_accuracy: 0.8400\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 11s 245ms/step - loss: 0.3297 - accuracy: 0.8650 - val_loss: 0.3583 - val_accuracy: 0.8371\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 11s 244ms/step - loss: 0.3185 - accuracy: 0.8721 - val_loss: 0.3441 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 10s 234ms/step - loss: 0.3201 - accuracy: 0.8607 - val_loss: 0.4312 - val_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 11s 245ms/step - loss: 0.3423 - accuracy: 0.8543 - val_loss: 0.3946 - val_accuracy: 0.8229\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 10s 234ms/step - loss: 0.3194 - accuracy: 0.8721 - val_loss: 0.3293 - val_accuracy: 0.8543\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 12s 264ms/step - loss: 0.2956 - accuracy: 0.8886 - val_loss: 0.3499 - val_accuracy: 0.8400\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 12s 260ms/step - loss: 0.2770 - accuracy: 0.8879 - val_loss: 0.3573 - val_accuracy: 0.8400\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 11s 242ms/step - loss: 0.3075 - accuracy: 0.8779 - val_loss: 0.3746 - val_accuracy: 0.8400\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 10s 238ms/step - loss: 0.2994 - accuracy: 0.8857 - val_loss: 0.3482 - val_accuracy: 0.8543\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 11s 251ms/step - loss: 0.2839 - accuracy: 0.8850 - val_loss: 0.3248 - val_accuracy: 0.8400\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 11s 246ms/step - loss: 0.2898 - accuracy: 0.8800 - val_loss: 0.3123 - val_accuracy: 0.8600\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 12s 274ms/step - loss: 0.2615 - accuracy: 0.9043 - val_loss: 0.3082 - val_accuracy: 0.8543\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 10s 235ms/step - loss: 0.2573 - accuracy: 0.9000 - val_loss: 0.3093 - val_accuracy: 0.8543\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 10s 230ms/step - loss: 0.2610 - accuracy: 0.9000 - val_loss: 0.3361 - val_accuracy: 0.8543\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 10s 237ms/step - loss: 0.2739 - accuracy: 0.8857 - val_loss: 0.3042 - val_accuracy: 0.8486\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 11s 249ms/step - loss: 0.2518 - accuracy: 0.9050 - val_loss: 0.3329 - val_accuracy: 0.8457\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 11s 244ms/step - loss: 0.2406 - accuracy: 0.9029 - val_loss: 0.2951 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 10s 231ms/step - loss: 0.2581 - accuracy: 0.8979 - val_loss: 0.3817 - val_accuracy: 0.8314\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 11s 241ms/step - loss: 0.2488 - accuracy: 0.9021 - val_loss: 0.3329 - val_accuracy: 0.8486\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 10s 236ms/step - loss: 0.2493 - accuracy: 0.9086 - val_loss: 0.3461 - val_accuracy: 0.8400\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 10s 233ms/step - loss: 0.2401 - accuracy: 0.9100 - val_loss: 0.3214 - val_accuracy: 0.8600\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 10s 238ms/step - loss: 0.2296 - accuracy: 0.9143 - val_loss: 0.2936 - val_accuracy: 0.8857\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 10s 231ms/step - loss: 0.2291 - accuracy: 0.9121 - val_loss: 0.3046 - val_accuracy: 0.8657\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 10s 228ms/step - loss: 0.2293 - accuracy: 0.9207 - val_loss: 0.3198 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 10s 228ms/step - loss: 0.2168 - accuracy: 0.9200 - val_loss: 0.2954 - val_accuracy: 0.8571\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 10s 229ms/step - loss: 0.2089 - accuracy: 0.9257 - val_loss: 0.3143 - val_accuracy: 0.8629\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 10s 234ms/step - loss: 0.2163 - accuracy: 0.9214 - val_loss: 0.2792 - val_accuracy: 0.8857\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 11s 241ms/step - loss: 0.2163 - accuracy: 0.9186 - val_loss: 0.2825 - val_accuracy: 0.8714\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 10s 237ms/step - loss: 0.2210 - accuracy: 0.9186 - val_loss: 0.3043 - val_accuracy: 0.8657\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 10s 232ms/step - loss: 0.1983 - accuracy: 0.9286 - val_loss: 0.2929 - val_accuracy: 0.8686\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 10s 231ms/step - loss: 0.2019 - accuracy: 0.9186 - val_loss: 0.2921 - val_accuracy: 0.8629\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 12s 278ms/step - loss: 0.1974 - accuracy: 0.9279 - val_loss: 0.2769 - val_accuracy: 0.8886\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 14s 310ms/step - loss: 0.2031 - accuracy: 0.9164 - val_loss: 0.3137 - val_accuracy: 0.8686\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 11s 254ms/step - loss: 0.2233 - accuracy: 0.9107 - val_loss: 0.2828 - val_accuracy: 0.8686\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 12s 279ms/step - loss: 0.1867 - accuracy: 0.9357 - val_loss: 0.2758 - val_accuracy: 0.8657\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 11s 239ms/step - loss: 0.1827 - accuracy: 0.9314 - val_loss: 0.2840 - val_accuracy: 0.8800\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 11s 252ms/step - loss: 0.1821 - accuracy: 0.9307 - val_loss: 0.2710 - val_accuracy: 0.8743\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 12s 272ms/step - loss: 0.1861 - accuracy: 0.9393 - val_loss: 0.3325 - val_accuracy: 0.8543\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 11s 244ms/step - loss: 0.1799 - accuracy: 0.9329 - val_loss: 0.2722 - val_accuracy: 0.8829\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 11s 247ms/step - loss: 0.1885 - accuracy: 0.9250 - val_loss: 0.3039 - val_accuracy: 0.8714\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 11s 253ms/step - loss: 0.2005 - accuracy: 0.9271 - val_loss: 0.2844 - val_accuracy: 0.8914\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 11s 254ms/step - loss: 0.1702 - accuracy: 0.9386 - val_loss: 0.3507 - val_accuracy: 0.8429\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 11s 262ms/step - loss: 0.1868 - accuracy: 0.9314 - val_loss: 0.2813 - val_accuracy: 0.8743\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 11s 247ms/step - loss: 0.1603 - accuracy: 0.9414 - val_loss: 0.2667 - val_accuracy: 0.8829\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 12s 263ms/step - loss: 0.1667 - accuracy: 0.9400 - val_loss: 0.3597 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 11s 248ms/step - loss: 0.1585 - accuracy: 0.9421 - val_loss: 0.3392 - val_accuracy: 0.8714\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 10s 237ms/step - loss: 0.1699 - accuracy: 0.9364 - val_loss: 0.2840 - val_accuracy: 0.8629\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 11s 240ms/step - loss: 0.1589 - accuracy: 0.9414 - val_loss: 0.2701 - val_accuracy: 0.8686\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 11s 240ms/step - loss: 0.1521 - accuracy: 0.9421 - val_loss: 0.2903 - val_accuracy: 0.8686\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 10s 234ms/step - loss: 0.1674 - accuracy: 0.9421 - val_loss: 0.2866 - val_accuracy: 0.8686\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 10s 232ms/step - loss: 0.1446 - accuracy: 0.9471 - val_loss: 0.2871 - val_accuracy: 0.8657\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 10s 235ms/step - loss: 0.1651 - accuracy: 0.9364 - val_loss: 0.2959 - val_accuracy: 0.8657\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 11s 239ms/step - loss: 0.1519 - accuracy: 0.9464 - val_loss: 0.2861 - val_accuracy: 0.8800\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.1528 - accuracy: 0.9464Restoring model weights from the end of the best epoch: 86.\n",
      "44/44 [==============================] - 10s 235ms/step - loss: 0.1528 - accuracy: 0.9464 - val_loss: 0.3825 - val_accuracy: 0.8514\n",
      "Epoch 96: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    class_weight = class_weights,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 1s - loss: 0.3376 - accuracy: 0.8630 - 793ms/epoch - 57ms/step\n",
      "Test Loss: 0.3376486003398895\n",
      "Test Accuracy: 0.8630136847496033\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 60ms/step\n",
      "Predicted Classes:  [0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1\n",
      " 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1\n",
      " 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1\n",
      " 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0\n",
      " 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0\n",
      " 1 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0\n",
      " 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1\n",
      " 1 0 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0\n",
      " 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# 예측 수행 (확률 값 반환)\n",
    "predictions = model.predict(X_test)  # 이진 분류에서는 sigmoid 출력\n",
    "\n",
    "# 0.5를 기준으로 클래스 결정\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"Predicted Classes: \", predicted_classes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-dl-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
