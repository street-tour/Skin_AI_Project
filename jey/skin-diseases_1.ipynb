{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tf_keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# zip_file = 'D:\\\\Workspace\\\\final\\\\jey\\\\IMG_CLASSES.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_folder = \"D:\\\\Workspace\\\\final\\\\jey\\\\content\\\\skin-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일이 D:\\Workspace\\final\\jey\\content\\skin-data폴더에 압축 해제되었습니다\n"
     ]
    }
   ],
   "source": [
    "# with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "#  zip_ref.extractall(extract_folder)\n",
    "# print(f\"파일이 {extract_folder}폴더에 압축 해제되었습니다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Eczema 1677\n",
    "2. Melanoma 15.75k\n",
    "3. Atopic Dermatitis - 1.25k\n",
    "4. Basal Cell Carcinoma (BCC) 3323\n",
    "5. Melanocytic Nevi (NV) - 7970\n",
    "6. Benign Keratosis-like Lesions (BKL) 2624\n",
    "7. Psoriasis pictures Lichen Planus and related diseases - 2k\n",
    "8. Seborrheic Keratoses and other Benign Tumors - 1.8k\n",
    "9. Tinea Ringworm Candidiasis and other Fungal Infections - 1.7k\n",
    "10. Warts Molluscum and other Viral Infections - 2103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 1: 1173개 train, 251개 val, 253개 test로 분리 완료\n",
      "클래스 2: 2198개 train, 471개 val, 471개 test로 분리 완료\n",
      "클래스 3: 879개 train, 188개 val, 190개 test로 분리 완료\n",
      "클래스 4: 2326개 train, 498개 val, 499개 test로 분리 완료\n",
      "클래스 5: 4499개 train, 964개 val, 965개 test로 분리 완료\n",
      "클래스 6: 1455개 train, 311개 val, 313개 test로 분리 완료\n",
      "클래스 7: 1438개 train, 308개 val, 309개 test로 분리 완료\n",
      "클래스 8: 1292개 train, 277개 val, 278개 test로 분리 완료\n",
      "클래스 9: 1191개 train, 255개 val, 256개 test로 분리 완료\n",
      "클래스 10: 1472개 train, 315개 val, 316개 test로 분리 완료\n",
      "데이터셋 분리 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# 경로 설정\n",
    "# base_dir = r\"D:\\\\Workspace\\\\final\\\\jey\\\\content\\\\skin-data\"  # 'train' 폴더가 있는 디렉터리\n",
    "# split_dir = r\"D:\\\\Workspace\\\\final\\\\jey\\\\content\\\\skin-data\"  # train, val, test 폴더를 저장할 폴더\n",
    "\n",
    "# train, test, val 폴더 만들기\n",
    "# os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "# 클래스별로 train, val, test 폴더를 만들기\n",
    "# for label in range(1, 11):  # 클래스 1~10\n",
    "#     class_folder = os.path.join(base_dir, str(label))\n",
    "#     if not os.path.exists(class_folder):\n",
    "#         print(f\"경고: {class_folder} 디렉터리가 존재하지 않습니다.\")\n",
    "#         continue\n",
    "\n",
    "    # 각 클래스 폴더에 대해 train, val, test 폴더 만들기\n",
    "#     train_folder = os.path.join(split_dir, 'train', str(label))\n",
    "#     val_folder = os.path.join(split_dir, 'val', str(label))\n",
    "#     test_folder = os.path.join(split_dir, 'test', str(label))\n",
    "\n",
    "#     os.makedirs(train_folder, exist_ok=True)\n",
    "#     os.makedirs(val_folder, exist_ok=True)\n",
    "#     os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    # 클래스별 이미지 파일 리스트\n",
    "#     images = os.listdir(class_folder)\n",
    "#     random.shuffle(images)  # 이미지 셔플\n",
    "\n",
    "    # 데이터 분할 비율\n",
    "#     total_images = len(images)\n",
    "#     train_size = int(total_images * 0.7)  # 70% 훈련용\n",
    "#     val_size = int(total_images * 0.15)  # 15% 검증용\n",
    "#     test_size = total_images - train_size - val_size  # 나머지 15%는 테스트용\n",
    "\n",
    "    # 분할된 이미지 리스트\n",
    "#     train_images = images[:train_size]\n",
    "#     val_images = images[train_size:train_size + val_size]\n",
    "#     test_images = images[train_size + val_size:]\n",
    "\n",
    "    # 이미지 복사 함수\n",
    "#     def copy_images(image_list, src_folder, dest_folder):\n",
    "#         for image in image_list:\n",
    "#             src_path = os.path.join(src_folder, image)\n",
    "#             dest_path = os.path.join(dest_folder, image)\n",
    "#             shutil.copy(src_path, dest_path)\n",
    "\n",
    "    # 이미지 복사\n",
    "#     copy_images(train_images, class_folder, train_folder)\n",
    "#     copy_images(val_images, class_folder, val_folder)\n",
    "#     copy_images(test_images, class_folder, test_folder)\n",
    "\n",
    "#     print(f\"클래스 {label}: {train_size}개 train, {val_size}개 val, {test_size}개 test로 분리 완료\")\n",
    "\n",
    "# print(\"데이터셋 분리 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'content/skin-data/train'\n",
    "test_dir = 'content/skin-data/test'\n",
    "val_dir = 'content/skin-data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip = True,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, preprocessing_function=preprocess_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 크기: 720x472\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = 'content/skin-data/test/1/t-03DermatitisArm.jpg'\n",
    "image = Image.open(image_path)\n",
    "width, height = image.size\n",
    "\n",
    "print(f\"이미지 크기: {width}x{height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17923 images belonging to 10 classes.\n",
      "Found 3838 images belonging to 10 classes.\n",
      "Found 3850 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(512, 512),  # 이미지 크기 조정\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # 다중 클래스 분류\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(512, 512),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(512, 512),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">524288</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">67,108,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m2048\u001b[0m)   │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m524288\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m67,108,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,697,994</span> (345.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m90,697,994\u001b[0m (345.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,110,282</span> (256.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,110,282\u001b[0m (256.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten,  Dropout\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.2094 - loss: 234.1531"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\human-dl-env\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5084s\u001b[0m 9s/step - accuracy: 0.2095 - loss: 233.8352 - val_accuracy: 0.2508 - val_loss: 2.1778\n",
      "Epoch 2/5\n",
      "\u001b[1m  1/560\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07:40\u001b[0m 7s/step - accuracy: 0.3438 - loss: 2.1157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\human-dl-env\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m811s\u001b[0m 1s/step - accuracy: 0.3438 - loss: 2.1157 - val_accuracy: 0.2505 - val_loss: 2.1782\n",
      "Epoch 3/5\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5030s\u001b[0m 9s/step - accuracy: 0.2459 - loss: 7.8789 - val_accuracy: 0.2516 - val_loss: 2.1769\n",
      "Epoch 4/5\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m812s\u001b[0m 1s/step - accuracy: 0.2500 - loss: 2.1712 - val_accuracy: 0.2513 - val_loss: 2.1773\n",
      "Epoch 5/5\n",
      "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5044s\u001b[0m 9s/step - accuracy: 0.2525 - loss: 2.1807 - val_accuracy: 0.2508 - val_loss: 2.1784\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m834s\u001b[0m 7s/step - accuracy: 0.2484 - loss: 2.1794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1785027980804443, 0.2506493628025055]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-dl-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
