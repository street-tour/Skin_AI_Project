{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# ZIP 파일 경로\n",
    "zip_file_path = '/content/drive/MyDrive/Final_Project/Jun/korean 01 data (3).zip'  # 업로드한 ZIP 파일 이름\n",
    "\n",
    "# ZIP 파일 압축 해제\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('korean_01_data')  # 'extracted_folder'는 압축 해제할 폴더 이름\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# ZIP 파일 경로\n",
    "zip_file_path = '/content/drive/MyDrive/Final_Project/Jun/jsonfile (3).zip'  # 업로드한 ZIP 파일 이름\n",
    "\n",
    "# ZIP 파일 압축 해제\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('jsonfile')  # 'extracted_folder'는 압축 해제할 폴더 이름\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 로드\n",
    "def load_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.resize(img , (256,256))\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json 파일 로드\n",
    "def load_json(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # gender = 1 if data['info']['gender'] =='F' else 0\n",
    "    # skin_type = data['info']['skin_type']\n",
    "    # sensitive = data['info']['sensitive']\n",
    "\n",
    "    pigmentation = data['annotations']['forehead_wrinkle']\n",
    "\n",
    "    return pigmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_dir = r\"/content/korean_01_data\"\n",
    "json_dir = r\"/content/jsonfile\"\n",
    "\n",
    "images = []\n",
    "metadata = []\n",
    "\n",
    "four_or_five_path = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for main_folder in os.listdir(image_dir):  # 'digit cam', 'pad', 'cell phone'\n",
    "    main_folder_path = os.path.join(image_dir, main_folder)\n",
    "    if os.path.isdir(main_folder_path):  # 메인 폴더인지 확인\n",
    "        for sub_folder in os.listdir(main_folder_path):  # '0001', '0002', '0003'\n",
    "            sub_folder_path = os.path.join(main_folder_path, sub_folder)\n",
    "            if os.path.isdir(sub_folder_path):  # 서브 폴더인지 확인\n",
    "                for filename in os.listdir(sub_folder_path):  # 이미지 파일들\n",
    "                    if filename.endswith('.jpg'):  # .jpg 파일만 처리\n",
    "                        image_path = os.path.join(sub_folder_path, filename)\n",
    "\n",
    "                        # # 여기서 특정 조건에 맞는 파일만 선택하도록 수정\n",
    "                        # if 'F' not in filename:  # L15가 포함된 파일만 선택\n",
    "                        #     continue  # L15가 포함되지 않으면 건너뜀\n",
    "\n",
    "\n",
    "                        # JSON 파일명 생성: 'cropped_' 제거하고 '.jpg' -> '.json'\n",
    "                        json_filename = filename.replace('cropped_', '').replace('.jpg', '')\n",
    "\n",
    "                        # json_dir도 image_dir처럼 동일한 폴더 구조를 반영하여 경로 설정\n",
    "                        json_folder_path = os.path.join(json_dir, main_folder, sub_folder)\n",
    "                        json_path = os.path.join(json_folder_path, json_filename)  # JSON 파일 경로\n",
    "\n",
    "\n",
    "                        # 이미지와 JSON 로드\n",
    "                        image = load_image(image_path)\n",
    "                        # if image is None:\n",
    "                        #     continue  # 이미지 로드 실패시 건너뛰기\n",
    "                        pigmentation = load_json(json_path)\n",
    "\n",
    "                        if pigmentation in [1,6]:\n",
    "                            continue\n",
    "\n",
    "                        if pigmentation in [0,2,3,4,5]:\n",
    "                            four_or_five_path.append(json_path)\n",
    "\n",
    "                            if pigmentation in [0,2]:\n",
    "                                pigmentation = 0\n",
    "                            elif pigmentation in [3,4,5]:\n",
    "                                pigmentation = 1\n",
    "\n",
    "\n",
    "\n",
    "                        images.append(image)  # images 리스트에 추가\n",
    "                        metadata.append(pigmentation)  # metadata 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = ['Pigmentation']\n",
    "metadata_df = pd.DataFrame(metadata, columns =columns)\n",
    "metadata_df['Pigmentation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트를 numpy 배열로 변환\n",
    "metadata = np.array(metadata)\n",
    "\n",
    "# 데이터 준비\n",
    "X = np.array(images, dtype=np.float32)\n",
    "y = np.array(metadata, dtype=np.float32)  # 타겟 (pigmentation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 이미지와 메타데이터를 함께 train_test_split에 전달\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 결과\n",
    "X_train_images = X_train\n",
    "X_val_images = X_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "# 이미지 입력\n",
    "image_input = Input(shape=(256, 256, 3), name='image_input')\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01), kernel_initializer='he_normal')(image_input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(64,(3,3), activation='relu', kernel_regularizer=l2(0.01), kernel_initializer='he_normal')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01), kernel_initializer='he_normal')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3, 3), activation='swish', kernel_regularizer=l2(0.01), kernel_initializer='he_normal')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(512,(3,3), activation='relu', kernel_regularizer=l2(0.01), kernel_initializer='he_normal')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# x = layers.Conv2D(1024, (3, 3), activation='swish',kernel_regularizer=l2(0.01), kernel_initializer='he_normal')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.Conv2D(2048,(1,1), activation='swish',kernel_regularizer=l2(0.01), kernel_initializer='he_normal')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.Conv2D(4096,(3,3), activation='swish',kernel_regularizer=l2(0.01), kernel_initializer='he_normal')(x)\n",
    "# x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)  # Global Average Pooling\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "x = layers.Dense(512, activation='swish', kernel_regularizer=l2(0.01), kernel_initializer='he_normal')(x)  # 더 큰 Dense 레이어\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# 출력 레이어\n",
    "output = layers.Dense(1, activation='sigmoid')(x)  # 이진 분류\n",
    "\n",
    "# 모델 생성\n",
    "model = models.Model(inputs=image_input, outputs=output)\n",
    "\n",
    "# 모델 컴파일\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00005)  # 학습률 조정\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약 출력\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models, Input\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# # Residual Block 정의\n",
    "# def residual_block(x, filters):\n",
    "#     shortcut = x\n",
    "#     # 채널 수를 맞추기 위해 1x1 컨볼루션 추가 (Projection Shortcut)\n",
    "#     if x.shape[-1] != filters:\n",
    "#         shortcut = layers.Conv2D(filters, (1, 1), padding='same', kernel_regularizer=l2(0.01))(shortcut)\n",
    "#         shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "#     # Residual 경로\n",
    "#     x = layers.Conv2D(filters, (3, 3), padding='same', activation='swish', kernel_regularizer=l2(0.01))(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Conv2D(filters, (3, 3), padding='same', activation=None, kernel_regularizer=l2(0.01))(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "\n",
    "#     # 입력(shortcut)과 출력(x)을 더하기\n",
    "#     x = layers.Add()([x, shortcut])\n",
    "#     x = layers.Activation('swish')(x)\n",
    "#     return x\n",
    "\n",
    "# # 이미지 입력\n",
    "# image_input = Input(shape=(256, 256, 3), name='image_input')\n",
    "\n",
    "# # 첫 번째 컨볼루션 레이어 (초기 입력 처리)\n",
    "# x = layers.Conv2D(64, (3, 3), activation='swish', kernel_regularizer=l2(0.01), kernel_initializer='he_normal')(image_input)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# # Residual Block 적용\n",
    "# x = residual_block(x, 64)  # 필터 수 64\n",
    "# x = residual_block(x, 128)  # 필터 수 128\n",
    "# x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# x = residual_block(x, 256)  # 필터 수 256\n",
    "# x = residual_block(x, 512)  # 필터 수 512\n",
    "# x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# # Global Average Pooling\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# # Fully Connected Layer\n",
    "# x = layers.Dense(1024, activation='swish', kernel_regularizer=l2(0.01), kernel_initializer='he_normal')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# # 출력 레이어\n",
    "# output = layers.Dense(1, activation='sigmoid')(x)  # 이진 분류\n",
    "\n",
    "# # 모델 생성\n",
    "# model = models.Model(inputs=image_input, outputs=output)\n",
    "\n",
    "# # 모델 컴파일\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.00005)  # 학습률 조정\n",
    "# model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # 모델 요약 출력\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 조기 종료 콜백 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # val_loss를 모니터링\n",
    "    patience=20,          # 개선되지 않은 에포크를 3번 참음\n",
    "    restore_best_weights=True  # 최상의 모델 가중치를 복원\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train_images,  # X_train_metadata 대신 y_train 사용 (pigmentation만 필요)\n",
    "    y_train,  # 타겟 라벨\n",
    "    validation_data=(X_val_images, y_val),  # 검증 데이터도 동일하게 전달\n",
    "    epochs=300,\n",
    "    batch_size=64,  # 올려볼것 32 64\n",
    "    #callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 학습이 완료되면 학습 과정에서의 손실과 메트릭스를 확인할 수 있습니다.\n",
    "print(\"Training History: \", history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    {'image_input': X_val_images, 'metadata_input': y_val},  # 검증 데이터에서 metadata_input은 pigmentation만 사용\n",
    "    y_val  # 검증 데이터의 실제 레이블 (pigmentation 값)\n",
    ")\n",
    "\n",
    "print(\"Test Loss: \", test_loss)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "\n",
    "\n",
    "# 0.58 0.56\n",
    "# 3으로 합친 후 : 0.569, stratify = y : 0.538\n",
    "# 모든 데이터 합친 후 : 0.52\n",
    "\n",
    "# 0.46\n",
    "# 0.56 batch normalization\n",
    "# 0.40 0.0001\n",
    "# 0.19 0.25  0.54 메타데이터 층 증가\n",
    "# 0.62(과대적합)\n",
    "# dropout(0.5) 0.678\n",
    "# Dense만 Dropout 0.64\n",
    "# dropout 추가 0.63(과대적합)\n",
    "\n",
    "# 이진분류 0.668\n",
    "\n",
    "\n",
    "\n",
    "# swish 0.00001 == 0.665\n",
    "# 300epoch ==0.7\n",
    "# 450 epcoh ==0.73\n",
    "# 400 epoch = 0.68\n",
    "# 500 epoch = 0.71\n",
    "# 600 epoch = 0.76\n",
    "# 700 epoch = 0.79\n",
    "# 900 epoch = 0.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)  # 첫 번째 그래프 (좌측)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 학습 정확도 (accuracy) 및 검증 정확도 (val_accuracy) 그래프\n",
    "plt.subplot(1, 2, 2)  # 두 번째 그래프 (우측)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 그래프를 화면에 표시\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model76-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-dl-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
