{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 로드\n",
    "def load_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.resize(img , (256,256))\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json 파일 로드\n",
    "def load_json(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    gender = 1 if data['info']['gender'] =='F' else 0\n",
    "    skin_type = data['info']['skin_type']\n",
    "    sensitive = data['info']['sensitive']\n",
    "\n",
    "    pigmentation = data['annotations']['forehead_wrinkle']\n",
    "\n",
    "    return gender, skin_type, sensitive, pigmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import os\n",
    "\n",
    "image_dir = r\"D:\\data\\korean 01 data\"\n",
    "json_dir = r\"D:\\data\\jsonfile\"\n",
    "\n",
    "images = []\n",
    "metadata = []\n",
    "\n",
    "four_or_five_path = []\n",
    "\n",
    "for main_folder in os.listdir(image_dir):  # 'digit cam', 'pad', 'cell phone'\n",
    "    main_folder_path = os.path.join(image_dir, main_folder)\n",
    "    if os.path.isdir(main_folder_path):  # 메인 폴더인지 확인\n",
    "        for sub_folder in os.listdir(main_folder_path):  # '0001', '0002', '0003'\n",
    "            sub_folder_path = os.path.join(main_folder_path, sub_folder)\n",
    "            if os.path.isdir(sub_folder_path):  # 서브 폴더인지 확인\n",
    "                for filename in os.listdir(sub_folder_path):  # 이미지 파일들\n",
    "                    if filename.endswith('.jpg'):  # .jpg 파일만 처리\n",
    "                        image_path = os.path.join(sub_folder_path, filename)\n",
    "\n",
    "                        # 여기서 특정 조건에 맞는 파일만 선택하도록 수정\n",
    "                        if 'F' not in filename:  # L15가 포함된 파일만 선택\n",
    "                            continue  # L15가 포함되지 않으면 건너뜀\n",
    "\n",
    "\n",
    "                        # JSON 파일명 생성: 'cropped_' 제거하고 '.jpg' -> '.json'\n",
    "                        json_filename = filename.replace('cropped_', '').replace('.jpg', '')\n",
    "\n",
    "                        # json_dir도 image_dir처럼 동일한 폴더 구조를 반영하여 경로 설정\n",
    "                        json_folder_path = os.path.join(json_dir, main_folder, sub_folder)\n",
    "                        json_path = os.path.join(json_folder_path, json_filename)  # JSON 파일 경로\n",
    "\n",
    "\n",
    "                        # 이미지와 JSON 로드\n",
    "                        image = load_image(image_path)\n",
    "                        if image is None:\n",
    "                            continue  # 이미지 로드 실패시 건너뛰기\n",
    "                        gender, skin_type, sensitive, pigmentation = load_json(json_path)\n",
    "\n",
    "                        if pigmentation in [0,1,2,3,4,5,6]:\n",
    "                            four_or_five_path.append(json_path)\n",
    "\n",
    "                            if pigmentation in [0,1]:\n",
    "                                pigmentation = 0\n",
    "                            elif pigmentation in [2,3]:\n",
    "                                pigmentation = 1\n",
    "                            elif pigmentation in [4,5, 6]:\n",
    "                                pigmentation = 2\n",
    "\n",
    "\n",
    "\n",
    "                        images.append(image)  # images 리스트에 추가\n",
    "                        metadata.append([gender, skin_type, sensitive, pigmentation])  # metadata 리스트에 추가\n",
    "\n",
    "\n",
    "# 리스트를 numpy 배열로 변환\n",
    "metadata = np.array(metadata)\n",
    "\n",
    "# 데이터 준비\n",
    "X = np.array(images)\n",
    "X_metadata = np.array(metadata[:, :-1])  # pigment 제외한 나머지 메타데이터\n",
    "y = metadata[:, -1]  # 타겟 (pigmentation)\n",
    "\n",
    "# 이미지와 메타데이터를 함께 train_test_split에 전달\n",
    "X_train, X_val, X_train_metadata, X_val_metadata, y_train, y_val = train_test_split(\n",
    "    X, X_metadata, y, test_size=0.2, random_state=42,stratify = y\n",
    ")\n",
    "\n",
    "# 결과\n",
    "X_train_images = X_train\n",
    "X_val_images = X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " image_input (InputLayer)    [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 254, 254, 64)         1792      ['image_input[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 254, 254, 64)         256       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 64)         0         ['batch_normalization[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 128)        73856     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 125, 125, 128)        512       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 128)          0         ['batch_normalization_1[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 128)          147584    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 60, 60, 128)          512       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 128)          0         ['batch_normalization_2[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 256)          295168    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 28, 28, 256)          1024      ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 256)          0         ['batch_normalization_3[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 512)          1180160   ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 12, 12, 512)          2048      ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 6, 6, 512)            0         ['batch_normalization_4[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " metadata_input (InputLayer  [(None, 3)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 1024)           4719616   ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128)                  512       ['metadata_input[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 4, 4, 1024)           4096      ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 128)                  512       ['dense_1[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 2, 2, 1024)           0         ['batch_normalization_5[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 256)                  33024     ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 1024)                 0         ['max_pooling2d_5[0][0]']     \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 256)                  1024      ['dense_2[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 1049600   ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 512)                  131584    ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 1024)                 4096      ['dense[0][0]']               \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 512)                  2048      ['dense_3[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 1024)                 0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 512)                  0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 1536)                 0         ['dropout[0][0]',             \n",
      "                                                                     'dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 3)                    4611      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7653635 (29.20 MB)\n",
      "Trainable params: 7645571 (29.17 MB)\n",
      "Non-trainable params: 8064 (31.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "\n",
    "image_input = Input(shape=(256, 256, 3), name='image_input')\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(image_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(1024,(3,3), activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)  # Global Average Pooling\n",
    "\n",
    "x = layers.Dense(1024, activation='relu')(x)  # 더 큰 Dense 레이어\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "metadata_input = Input(shape=(3,), name='metadata_input')\n",
    "y = layers.Dense(128, activation='relu')(metadata_input)  # 더 큰 Dense 레이어\n",
    "y = layers.BatchNormalization()(y)\n",
    "y = layers.Dense(256, activation='relu')(y)\n",
    "y = layers.BatchNormalization()(y)\n",
    "y = layers.Dense(512, activation='relu')(y)\n",
    "y = layers.BatchNormalization()(y)\n",
    "y = layers.Dropout(0.5)(y)\n",
    "\n",
    "combined = layers.concatenate([x, y])\n",
    "output = layers.Dense(3, activation='softmax')(combined)\n",
    "\n",
    "model = models.Model(inputs=[image_input, metadata_input], outputs=output)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) # 낮추기\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 사전학습 모델 \n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models, Input\n",
    "# from tensorflow.keras.applications import ResNet50\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# image_input = Input(shape=(224, 224, 3), name='image_input')\n",
    "\n",
    "# # ResNet50을 사전학습된 가중치로 불러옴 (include_top=False는 분류용 마지막 레이어 제외)\n",
    "# resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))(image_input)\n",
    "# x = layers.GlobalAveragePooling2D()(resnet)  # ResNet50의 출력은 GlobalAveragePooling2D로 처리\n",
    "\n",
    "# # 메타데이터 입력\n",
    "# metadata_input = Input(shape=(4,), name='metadata_input')\n",
    "# y = layers.Dense(32, activation='relu')(metadata_input)\n",
    "# y = layers.Dense(16, activation='relu')(y)\n",
    "\n",
    "# # 두 입력을 결합\n",
    "# combined = layers.concatenate([x, y])\n",
    "\n",
    "# # 최종 출력 레이어\n",
    "# output = layers.Dense(6, activation='softmax')(combined)\n",
    "\n",
    "# # 모델 정의\n",
    "# model2 = Model(inputs=[image_input, metadata_input], outputs=output)\n",
    "\n",
    "# # 모델 컴파일\n",
    "# model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # 모델 요약\n",
    "# model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 조기 종료 콜백 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # val_loss를 모니터링\n",
    "    patience=3,          # 개선되지 않은 에포크를 3번 참음\n",
    "    restore_best_weights=True  # 최상의 모델 가중치를 복원\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "37/37 [==============================] - 1285s 19s/step - loss: 1.9200 - accuracy: 0.4339 - val_loss: 1.4428 - val_accuracy: 0.4076\n",
      "Epoch 2/80\n",
      "37/37 [==============================] - 353s 10s/step - loss: 1.3222 - accuracy: 0.4978 - val_loss: 2.1073 - val_accuracy: 0.4076\n",
      "Epoch 3/80\n",
      "37/37 [==============================] - 335s 9s/step - loss: 1.2702 - accuracy: 0.4948 - val_loss: 3.7183 - val_accuracy: 0.4076\n",
      "Epoch 4/80\n",
      "37/37 [==============================] - 410s 11s/step - loss: 1.1245 - accuracy: 0.5298 - val_loss: 3.1851 - val_accuracy: 0.4076\n",
      "Epoch 5/80\n",
      " 5/37 [===>..........................] - ETA: 6:07 - loss: 1.2551 - accuracy: 0.4812"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_train_images, X_train_metadata],  # 두 입력을 리스트로 전달\n",
    "    y_train,  # 타겟 라벨\n",
    "    validation_data=([X_val_images, X_val_metadata], y_val),  # 검증 데이터도 동일하게 전달\n",
    "    epochs=80,\n",
    "    batch_size=64,\n",
    "    validation_batch_size = 64, # 올려볼것 32 64\n",
    "    #callbacks=[early_stopping]\n",
    ")\n",
    "# 학습이 완료되면 학습 과정에서의 손실과 메트릭스를 확인할 수 있습니다.\n",
    "\n",
    "print(\"Training History: \", history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 27s 1s/step - loss: 1.1994 - accuracy: 0.5233\n",
      "Test Loss:  1.1994446516036987\n",
      "Test Accuracy:  0.5233160853385925\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    {'image_input': X_val_images, 'metadata_input': X_val_metadata},  # 검증 데이터\n",
    "    y_val  # 검증 데이터의 실제 레이블\n",
    ")\n",
    "\n",
    "print(\"Test Loss: \", test_loss)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n",
    "\n",
    "# 0.58 0.56\n",
    "# 3으로 합친 후 : 0.569, stratify = y : 0.538\n",
    "# 모든 데이터 합친 후 : 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Skin_type</th>\n",
       "      <th>Sensitive</th>\n",
       "      <th>Pigmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2895 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Gender  Skin_type  Sensitive  Pigmentation\n",
       "0      55       1          3          0             3\n",
       "1      50       1          0          0             1\n",
       "2      24       1          0          0             0\n",
       "3      47       1          4          1             1\n",
       "4      55       1          3          0             3\n",
       "...   ...     ...        ...        ...           ...\n",
       "2890   25       1          1          0             1\n",
       "2891   24       1          1          0             1\n",
       "2892   23       1          1          0             1\n",
       "2893   26       1          1          1             1\n",
       "2894   28       1          3          1             1\n",
       "\n",
       "[2895 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns = ['Age', 'Gender', 'Skin_type', 'Sensitive','Pigmentation']\n",
    "metadata_df = pd.DataFrame(metadata, columns =columns)\n",
    "\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pigmentation\n",
       "1    1062\n",
       "2     696\n",
       "3     480\n",
       "4     228\n",
       "5     177\n",
       "6     135\n",
       "0     117\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['Pigmentation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-dl-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
